{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabd4a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "using SeisNoise, SeisIO, Plots\n",
    "using Dates \n",
    "using Plots\n",
    "using SeisDvv\n",
    "using CSV\n",
    "using Statistics\n",
    "using LinearAlgebra\n",
    "using Deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6d126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ncf_denoise function\n",
    "function ncf_denoise(img_to_denoise::Matrix{Float32}, mdate::Int64, ntau::Int64, nsv::Int64, nsv_to_rm::Int64, use_wiener::Bool, noise_power::Float64)\n",
    "    m, n = size(img_to_denoise)\n",
    "    nsv = min(nsv, m, n)\n",
    "\n",
    "    U, s, V = svd(img_to_denoise)\n",
    "    Xwiener = zeros(Float32, size(img_to_denoise))  # Ensure the type is Float32\n",
    "\n",
    "    for kk in (nsv_to_rm + 1):nsv\n",
    "        SV = Diagonal([kk == i ? s[kk] : 0 for i in 1:min(m, n)])\n",
    "\n",
    "        X = U * SV * V'\n",
    "\n",
    "        if use_wiener\n",
    "            # Convert X to Float64 if necessary\n",
    "            X64 = convert(Matrix{Float64}, X)\n",
    "            Xwiener += wiener(X64, X64, noise_power)\n",
    "        else\n",
    "            Xwiener += X\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if use_wiener\n",
    "        # Final Wiener filter application, converting Xwiener to Float64\n",
    "        Xwiener64 = convert(Matrix{Float64}, Xwiener)\n",
    "        return wiener(Xwiener64, Xwiener64, noise_power)\n",
    "    else\n",
    "        return Xwiener\n",
    "    end\n",
    "end\n",
    "\n",
    "# Convert UNIX timestamp to DateTime\n",
    "unixtimestamp_to_datetime(ts) = unix2datetime(ts)\n",
    "\n",
    "function find_indices_in_window(start_times, window_start, window_end)\n",
    "    return findall(t -> window_start <= unixtimestamp_to_datetime(t) <= window_end, start_times)\n",
    "end\n",
    "\n",
    "function stack_moving_window(corr_data, window_size_days, overlap_days)\n",
    "    window_size = Day(window_size_days)\n",
    "    overlap = Day(overlap_days)\n",
    "\n",
    "    # Initialize a matrix for the stacked correlations and a vector for the start times\n",
    "    stacked_correlations_matrix = Array{Float32}(undef, 8001, 0)\n",
    "    stacked_start_times = Float64[]\n",
    "\n",
    "    current_start_date = unixtimestamp_to_datetime(first(corr_data.t))\n",
    "\n",
    "    while current_start_date <= unixtimestamp_to_datetime(last(corr_data.t))\n",
    "        current_end_date = current_start_date + window_size - Day(1)\n",
    "        indices = find_indices_in_window(corr_data.t, current_start_date, current_end_date)\n",
    "\n",
    "        if length(indices) > 0\n",
    "            window_data = deepcopy(corr_data)\n",
    "            window_data.corr = corr_data.corr[:, indices]\n",
    "            stacked_corr = stack(window_data, allstack=true).corr\n",
    "\n",
    "            # Append the stacked correlation as a new column\n",
    "            stacked_correlations_matrix = hcat(stacked_correlations_matrix, stacked_corr)\n",
    "\n",
    "            # Append the start time of the window\n",
    "            push!(stacked_start_times, datetime2unix(current_start_date))\n",
    "        end\n",
    "\n",
    "        current_start_date += overlap\n",
    "    end\n",
    "\n",
    "    # Create a new CorrData instance with the stacked data\n",
    "    new_corr_data = deepcopy(corr_data)\n",
    "    new_corr_data.corr = stacked_correlations_matrix\n",
    "    new_corr_data.t = stacked_start_times\n",
    "\n",
    "    return new_corr_data\n",
    "end\n",
    "\n",
    "\n",
    "# Averaging function for causal and acausal parts\n",
    "function average_causal_acausal(corr, time)\n",
    "    averaged_corr = copy(corr)\n",
    "    causal_index = findfirst(time .>= 0)\n",
    "    acausal_index = findlast(time .< 0)\n",
    "\n",
    "    for k in 1:causal_index-1\n",
    "        if acausal_index - k + 1 > 0\n",
    "            averaged_corr[causal_index + k - 1] = (averaged_corr[acausal_index - k + 1] + averaged_corr[causal_index + k - 1]) / 2\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return averaged_corr\n",
    "end\n",
    "\n",
    "# Function to create an evenly spaced array\n",
    "function evenly_spaced(a, b, n)\n",
    "    h = (b - a) / (n - 1)\n",
    "    collect(a:h:b)\n",
    "end\n",
    "\n",
    "function update_progress_bar(current_step::Int, start_step::Int, end_step::Int)\n",
    "    total_steps = end_step - start_step\n",
    "    progress = (current_step - start_step) / total_steps\n",
    "    filled_length = round(Int, 50 * progress)\n",
    "    bar = repeat('â–ˆ', filled_length) * repeat(' ', 50 - filled_length)\n",
    "    print(\"\\rProgress: |$bar| $(round(progress * 100))% Complete\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e777e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "function ncf_denoise(img_to_denoise::Matrix{Float32}, mdate::Int64, ntau::Int64, nsv::Int64, nsv_to_rm::Int64, use_wiener::Bool, noise_power::Float64)\n",
    "    m, n = size(img_to_denoise)\n",
    "    nsv = min(nsv, m, n)  # Ensure nsv does not exceed the dimensions of the image\n",
    "\n",
    "    U, s, V = svd(img_to_denoise)  # Perform singular value decomposition\n",
    "    Xwiener = zeros(Float32, m, n)  # Initialize the result matrix of type Float32\n",
    "    \n",
    "    total_steps = nsv - nsv_to_rm  # Calculate total steps required for the loop\n",
    "    println(\"Starting denoising...\")  # Initial message before processing starts\n",
    "\n",
    "    for kk in (nsv_to_rm + 1):nsv\n",
    "        # Perform rank-1 updates using only significant singular values\n",
    "        Xwiener .+= U[:, kk] * s[kk] * V[:, kk]'  # Scale outer product by the singular value\n",
    "        \n",
    "        # Progress bar update\n",
    "        progress = (kk - nsv_to_rm) / total_steps  # Calculate progress ratio\n",
    "        filled_length = round(Int, 50 * progress)  # Calculate number of blocks to fill\n",
    "        bar = repeat('â–ˆ', filled_length) * repeat(' ', 50 - filled_length)  # Create progress bar\n",
    "        print(\"\\rProgress: |$bar| $(round(progress * 100))% Complete\")  # Print progress bar\n",
    "    end\n",
    "    \n",
    "    println(\"\\nDenoising completed.\")  # End message after processing completes\n",
    "\n",
    "    return Xwiener  # Return the reconstructed, denoised image\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8104ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = load_corr(\"/data/wsd02/maleen_data/C_test/OO.HYS14..BHZ.OO.HYSB1..BHZ.jld2\", \"ZZ\");\n",
    "#dd = load_corr(\"/data/wsd02/maleen_data/C_test/OO.HYSB1..BHE.OO.HYS14..BHE.jld2\", \"EE\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bcd3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO REMOVE CROSS CORRELATION FUNCTIONS THAT ARE BAD FROM THE STACK\n",
    "using Dates\n",
    "\n",
    "# Convert d.t to DateTime objects\n",
    "dt_dates = [unix2datetime(ts) for ts in d.t]\n",
    "\n",
    "# Define the date ranges to exclude\n",
    "exclude_ranges = [(DateTime(2016,8,15), DateTime(2017,2,21)),(DateTime(2017,3,5), DateTime(2017,7,14))]\n",
    "\n",
    "# Find indices of dates within the specified ranges\n",
    "indices_to_remove = findall(dt -> any(start_date <= dt <= end_date for (start_date, end_date) in exclude_ranges), dt_dates)\n",
    "d.t = deleteat!(d.t, indices_to_remove)\n",
    "# Identify all column indices\n",
    "total_columns = size(d.corr, 2)\n",
    "all_indices = 1:total_columns\n",
    "\n",
    "# Determine the indices of columns to keep\n",
    "indices_to_keep = setdiff(all_indices, indices_to_remove)\n",
    "\n",
    "# Update t.corr by keeping only the desired columns\n",
    "d.corr = d.corr[:, indices_to_keep];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccd58a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#facilitating HYS14/HYSB1\n",
    "ndaystack = 1\n",
    "inter = Day(ndaystack)\n",
    "d=stack(dd,interval=inter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1e6c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO REMOVE CROSS CORRELATION FUNCTIONS THAT ARE BAD FROM THE STACK\n",
    "using Dates\n",
    "\n",
    "# Convert d.t to DateTime objects\n",
    "dt_dates = [unix2datetime(ts) for ts in d.t]\n",
    "\n",
    "# Define the date ranges to exclude\n",
    "exclude_ranges = [(DateTime(2016,8,15), DateTime(2017,8,14))]\n",
    "\n",
    "# Find indices of dates within the specified ranges\n",
    "indices_to_remove = findall(dt -> any(start_date <= dt <= end_date for (start_date, end_date) in exclude_ranges), dt_dates)\n",
    "d.t = deleteat!(d.t, indices_to_remove)\n",
    "# Identify all column indices\n",
    "total_columns = size(d.corr, 2)\n",
    "all_indices = 1:total_columns\n",
    "\n",
    "# Determine the indices of columns to keep\n",
    "indices_to_keep = setdiff(all_indices, indices_to_remove)\n",
    "\n",
    "# Update t.corr by keeping only the desired columns\n",
    "d.corr = d.corr[:, indices_to_keep];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd4034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO REMOVE CROSS CORRELATION FUNCTIONS THAT ARE BAD FROM THE STACK\n",
    "using Dates\n",
    "\n",
    "# Convert d.t to DateTime objects\n",
    "dt_dates = [unix2datetime(ts) for ts in d.t]\n",
    "\n",
    "# Define the date ranges to exclude\n",
    "exclude_ranges = [(DateTime(2016,8,15), DateTime(2017,2,16)),(DateTime(2017,3,12), DateTime(2017,8,14)),(DateTime(2014,11,1), DateTime(2014,11,20),(DateTime(2020,6,15), DateTime(2021,8,1)))]\n",
    "\n",
    "# Find indices of dates within the specified ranges\n",
    "indices_to_remove = findall(dt -> any(start_date <= dt <= end_date for (start_date, end_date) in exclude_ranges), dt_dates)\n",
    "d.t = deleteat!(d.t, indices_to_remove)\n",
    "# Identify all column indices\n",
    "total_columns = size(d.corr, 2)\n",
    "all_indices = 1:total_columns\n",
    "\n",
    "# Determine the indices of columns to keep\n",
    "indices_to_keep = setdiff(all_indices, indices_to_remove)\n",
    "\n",
    "# Update t.corr by keeping only the desired columns\n",
    "d.corr = d.corr[:, indices_to_keep];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ced007",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TO REMOVE CROSS CORRELATION FUNCTIONS THAT ARE BAD FROM THE STACK\n",
    "using Dates\n",
    "\n",
    "# Convert d.t to DateTime objects\n",
    "dt_dates = [unix2datetime(ts) for ts in d.t]\n",
    "\n",
    "# Define the date ranges to exclude\n",
    "exclude_ranges = [(DateTime(2020,8,14), DateTime(2021,9,1)),(DateTime(2014,11,1), DateTime(2015,1,1))]\n",
    "\n",
    "# Find indices of dates within the specified ranges\n",
    "indices_to_remove = findall(dt -> any(start_date <= dt <= end_date for (start_date, end_date) in exclude_ranges), dt_dates)\n",
    "d.t = deleteat!(d.t, indices_to_remove)\n",
    "# Identify all column indices\n",
    "total_columns = size(d.corr, 2)\n",
    "all_indices = 1:total_columns\n",
    "\n",
    "# Determine the indices of columns to keep\n",
    "indices_to_keep = setdiff(all_indices, indices_to_remove)\n",
    "\n",
    "# Update t.corr by keeping only the desired columns\n",
    "d.corr = d.corr[:, indices_to_keep];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8620cc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess your data\n",
    "mnf = 0.8\n",
    "mxf = 3.0\n",
    "ndaystack = 60\n",
    "remove_nan!(d)\n",
    "\n",
    "allstk = stack(d, allstack=true)\n",
    "clean_up!(allstk, mnf, mxf)\n",
    "abs_max!(allstk)\n",
    "#inter = Day(1)\n",
    "#dailystk = stack(d, interval=inter)\n",
    "\n",
    "dailystk = stack_moving_window(d, ndaystack, 1)\n",
    "clean_up!(dailystk, mnf, mxf)\n",
    "abs_max!(dailystk)\n",
    "dailystk1=deepcopy(dailystk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9bb605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove_nan!(d)\n",
    "#dailystk = stack_moving_window(d, 60, 1)\n",
    "#abs_max!(dailystk)\n",
    "#allstk = stack(d, allstack=true)\n",
    "#abs_max!(allstk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa833c8b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(dailystk,size=(1000, 500),left_margin=20Plots.mm, right_margin=5Plots.mm, bottom_margin=10Plots.mm, dpi=200,xlim=[-60,60])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949b7ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lags = evenly_spaced(-100, 100, size(dailystk.corr, 1))\n",
    "\n",
    "# Find the index of the maximum absolute value in allstk.corr\n",
    "max_index = argmax((allstk.corr))\n",
    "\n",
    "# Find the corresponding lag value\n",
    "max_lag = lags[max_index]\n",
    "\n",
    "println(\"Index of maximum absolute value: \", max_index)\n",
    "println(\"Corresponding lag value: \", max_lag)\n",
    "max_lag=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e37131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denoise allstk and dailystk and store in the corrdata\n",
    "mdate = 10\n",
    "ntau = 10\n",
    "nsv =5\n",
    "nsv_to_rm = 0\n",
    "use_wiener = false\n",
    "\n",
    "# Estimate of the noise power (adjust based on your data)\n",
    "noise_power = 0.03  # Example value, adjust as needed\n",
    "\n",
    "allstk.corr = ncf_denoise(allstk.corr, mdate, ntau, nsv, nsv_to_rm, use_wiener, noise_power);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188253a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dailystk.corr = ncf_denoise(dailystk.corr, mdate, ntau, nsv, nsv_to_rm, use_wiener, noise_power);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8b2f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "fig=plot(dailystk,size=(1000, 500),left_margin=20Plots.mm, right_margin=5Plots.mm, bottom_margin=10Plots.mm, dpi=200,xlim=[-40,40],grid=:true)\n",
    "#savefig(fig, \"interstation083.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b91cd2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "using SeisNoise\n",
    "using Plots\n",
    "\n",
    "function plot_corr_heatmap(C::CorrData)\n",
    "    lags = -C.maxlag:1/C.fs:C.maxlag\n",
    "    times = Dates.format.(Dates.unix2datetime.(C.t), \"yyyy/m/d HH:MM\")\n",
    "\n",
    "    # Create the heatmap plot\n",
    "    p = heatmap(lags, times, C.corr',\n",
    "                size=(1000, 500), \n",
    "                left_margin=20Plots.mm, \n",
    "                right_margin=5Plots.mm, \n",
    "                bottom_margin=10Plots.mm, \n",
    "                dpi=200, \n",
    "                seriescolor=:balance, \n",
    "                ytickfontsize=10, \n",
    "                xtickfontsize=8,\n",
    "                xlim=[-60,60],\n",
    "                grid=:true,\n",
    "                legend=:false,\n",
    "                gridalpha=1.0,\n",
    "                gridlinewidth=2,\n",
    "                gridcolor=:black,\n",
    "                framestyle=:grid,)\n",
    "\n",
    "    # Add vertical lines at x = -1, -2, 0, 1, 2, 3, 4, 5\n",
    "    vlines = [-20, -30, 0, 2, 20, 30]\n",
    "    for x_val in vlines\n",
    "        vline!([x_val], color=:black, linewidth=1)\n",
    "    end\n",
    "\n",
    "    return p\n",
    "end\n",
    "\n",
    "# Assuming `CorrData` is a type from SeisNoise\n",
    "# Use the custom plotting function\n",
    "ppp = plot_corr_heatmap(dailystk)\n",
    "\n",
    "# Display the plot\n",
    "display(ppp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1893c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = Dates.format.(Dates.unix2datetime.(dailystk.t), \"yyyy/m/d HH:MM\")\n",
    "a=600\n",
    "b=1200\n",
    "plot(times,dailystk.corr[2000,:])\n",
    "plot!(times,dailystk.corr[3000,:])\n",
    "#plot!(a:b,dailystk.corr[4000,a:b])\n",
    "plot!(times,dailystk.corr[5000,:])\n",
    "plot!(times,dailystk.corr[6000,:])\n",
    "plot!(times,dailystk.corr[7000,:],ylim=[-0.05,0.05],size=(1000, 300),xrot = -30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a97ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6b2e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "using SeisNoise\n",
    "using Plots\n",
    "\n",
    "function plot_corr_heatmap(C::CorrData)\n",
    "    lags = -C.maxlag:1/C.fs:C.maxlag\n",
    "    times = Dates.format.(Dates.unix2datetime.(C.t), \"yyyy/m/d HH:MM\")\n",
    "\n",
    "    # Create the heatmap plot\n",
    "    p = heatmap(times,lags,C.corr,\n",
    "                size=(1000, 600), \n",
    "                left_margin=20Plots.mm, \n",
    "                right_margin=5Plots.mm, \n",
    "                bottom_margin=10Plots.mm, \n",
    "                dpi=200, \n",
    "                seriescolor=:balance, \n",
    "                ytickfontsize=10, \n",
    "                xtickfontsize=8,\n",
    "                xrotation=45,\n",
    "                xgrid=true,\n",
    "                ylim=[25,35],\n",
    "                grid=:true,\n",
    "                gridalpha=1.0,\n",
    "                gridlinewidth=2,\n",
    "                legend=:false,\n",
    "                gridcolor=:black,\n",
    "                framestyle=:grid,)\n",
    "\n",
    "    # Add vertical lines at x = -1, -2, 0, 1, 2, 3, 4, 5\n",
    "    vlines = [-50, -40, -20, -10, 0, 10, 20, 40, 50]\n",
    "    for x_val in vlines\n",
    "        hline!([x_val], color=:black, linewidth=1)\n",
    "        vline!([])\n",
    "    end\n",
    "\n",
    "    return p\n",
    "end\n",
    "\n",
    "# Assuming `CorrData` is a type from SeisNoise\n",
    "# Use the custom plotting function\n",
    "ppp = plot_corr_heatmap(dailystk)\n",
    "\n",
    "# Display the plot\n",
    "display(ppp)\n",
    "#savefig(ppp, \"HYSB1_35.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be792323",
   "metadata": {},
   "source": [
    "## Parallelized Stretching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40a4a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed\n",
    "\n",
    "# Add processes (if not already added)\n",
    "if nprocs() == 1  # Only the main process is running\n",
    "    addprocs(18)  # Adjust the number as needed\n",
    "end\n",
    "\n",
    "@everywhere begin\n",
    "    using SharedArrays, HDF5, Plots,SeisNoise, SeisIO, Plots\n",
    "    using Dates \n",
    "    using Plots\n",
    "    using SeisDvv\n",
    "    # Ensure all necessary modules are loaded in each worker\n",
    "\n",
    "    fs = 40.0     # sample frequency\n",
    "    win_len = 2.0  # sliding window length\n",
    "    win_step = 5.0 # sliding window step\n",
    "    tmin = 20.0\n",
    "    tmax = 40.0\n",
    "    dmn = -0.05 #0.15\n",
    "    dmx = 0.05 #0.15\n",
    "end\n",
    "\n",
    "# Define your data or load it in a way that each worker can access it\n",
    "# Assuming dailystk.corr is accessible to all workers, or needs to be distributed\n",
    "j = size(dailystk.corr, 2)\n",
    "dvt = SharedArray{Float64}(j)\n",
    "cct = SharedArray{Float64}(j)\n",
    "cctb = SharedArray{Float64}(j)\n",
    "\n",
    "@distributed for i = 1:j\n",
    "    S1 = Array(allstk.corr[:])\n",
    "    S2 = Array(dailystk.corr[:,i])\n",
    "    rel_tmin_index = Int(floor((tmin + 100+max_lag) * fs))\n",
    "    rel_tmax_index = Int(floor((tmax + 100+max_lag) * fs))\n",
    "    \n",
    "    window = collect(rel_tmin_index:rel_tmax_index)\n",
    "    fmin = mnf  # Ensure mnf is defined or loaded\n",
    "    fmax = mxf  # Ensure mxf is defined or loaded\n",
    "\n",
    "    function evenly_spaced(a, b, n)\n",
    "        h = (b - a) / (n - 1)\n",
    "        collect(a:h:b)\n",
    "    end\n",
    "\n",
    "    time = evenly_spaced(-100, 100, size(dailystk.corr, 1))\n",
    "    time = time.-max_lag\n",
    "\n",
    "    dvv_ts, cc_ts, cdp_Ts, eps_ts, err_ts, allC_ts = SeisDvv.stretching(S1, S2, time, window, fmin, fmax, dvmin=dmn, dvmax=dmx, ntrial=3000)\n",
    "    dvt[i] = dvv_ts\n",
    "    cct[i] = cc_ts\n",
    "    cctb[i] = cdp_Ts\n",
    "end\n",
    "\n",
    "println(\"Computation completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42231576",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = map(unix2datetime, dailystk.t);\n",
    "# Assuming datetime_vector is your 71-element Vector{DateTime} \n",
    "# and float_vector is your 71-element Vector{Float64}\n",
    "datetime_vector = dt;  # fill this with your data\n",
    "float_vector = dvt;  # fill this with your data\n",
    "cctfilter = cct;\n",
    "\n",
    "# Combine the vectors into a named tuple which CSV.File will interpret as a table\n",
    "data = (DateTime=datetime_vector, Float=float_vector,cct);\n",
    "\n",
    "# Set the threshold value\n",
    "threshold = 0.9\n",
    "\n",
    "# Filter the datetime and float vectors based on the threshold\n",
    "filtered_indices = cct .>= threshold;\n",
    "datetime_vector = datetime_vector[filtered_indices];\n",
    "float_vector = float_vector[filtered_indices];\n",
    "cctfilter = cct[filtered_indices];\n",
    "\n",
    "# Calculate the Interquartile Range (IQR)\n",
    "Q1 = quantile(float_vector, 0.1)#20)\n",
    "Q3 = quantile(float_vector, 0.9)#80)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calculate the lower and upper bounds to filter the outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter the vectors to remove the outliers\n",
    "dtf = DateTime[]\n",
    "dvtf = Float64[]\n",
    "cctf = Float64[]\n",
    "for i in 1:length(float_vector)\n",
    "    if float_vector[i] >= lower_bound && float_vector[i] <= upper_bound\n",
    "        push!(dtf, datetime_vector[i])\n",
    "        push!(dvtf, float_vector[i])\n",
    "        push!(cctf, cctfilter[i])\n",
    "    end\n",
    "end\n",
    "# Calculate the mean and standard deviation\n",
    "mean_value = mean(cct)\n",
    "std_deviation = std(dvtf)\n",
    "\n",
    "# Print the results\n",
    "println(\"Mean of the float vector: $mean_value\")\n",
    "println(\"Standard deviation of the float vector: $std_deviation\")\n",
    "\n",
    "# Sample datetime_vector and dvtf\n",
    "datetime_vector = dtf\n",
    "\n",
    "# Find the minimum and maximum dates in the datetime_vector\n",
    "min_date = minimum(datetime_vector)\n",
    "max_date = maximum(datetime_vector)\n",
    "\n",
    "# Generate all dates in the date rangeI'\n",
    "all_dates = collect(min_date:Day(ndaystack):max_date)\n",
    "\n",
    "# Find the dates that are in all_dates but not in datetime_vector (considering only the date part)\n",
    "missing_dates = setdiff(all_dates, datetime_vector)\n",
    "\n",
    "# Assuming dt, dvt, cct, and dailystk are defined\n",
    "#dt = map(unix2datetime, dailystk.t)\n",
    "ticks = dtf[1:100:end]\n",
    "tick = Dates.format.(ticks, \"yyyy-mm-dd\")\n",
    "\n",
    "# First subplot\n",
    "p1 = plot(scatter(dtf, dvtf), seriestype = :line, xticks = (ticks, tick), xrot = -30, ylabel=\"dv/v %\", legend=false)#,ylim=(-0.5, 0.5))\n",
    "plot!(dtf, dvtf, seriestype = :line, xticks = (ticks, tick), xrot = -30, legend=false)\n",
    "# For each missing date, add a vertical line to the plot\n",
    "#for date in missing_dates\n",
    "#    vline!(p1, [DateTime(date)], linecolor=:red, linewidth=2, linealpha=0.5, label=\"Missing Date\")\n",
    "#end\n",
    "\n",
    "\n",
    "# Second subplot\n",
    "p2 = plot(dtf, cctf, seriestype = :line, ylim = [0.6, 1], label = \"cc\", xticks = (ticks, tick), xrot = -30, left_margin = 10Plots.mm, ylabel=\"cc\", xlabel=\"Date\", legend=false)\n",
    "hline!([0.8], label=\"Threshold\", width=2, color=:red) # Adding a horizontal line at y=0.8\n",
    "\n",
    "# Third subplot\n",
    "p3 = plot(dailystk,xlim=[-10,10], left_margin = 10Plots.mm)\n",
    "\n",
    "# The layout now specifies a grid of 3 rows and 1 column and gives the third plot even more vertical space compared to the first two.\n",
    "l = @layout([a{0.3h}; b{0.2h}; c{0.5h}])\n",
    "\n",
    "# Combine the plots\n",
    "final_plot = plot(p1, p2, p3, layout = l, size = (1100, 1000), left_margin = 20Plots.mm, right_margin = 5Plots.mm)\n",
    "\n",
    "# Save the plot\n",
    "#savefig(final_plot, \"$(d.name)_t$(tmin)-$(tmax)_freq$(mnf)-$(mxf)_stk$(ndaystack)SVD5s.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18953b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "\n",
    "ticks = dtf[1:100:end]\n",
    "tick = Dates.format.(ticks, \"yyyy-mm-dd\")\n",
    "# Your data and plot setup here\n",
    "# Example: dtf, dvtf, cctf, ticks, tick\n",
    "\n",
    "# Define a color gradient\n",
    "my_colormap = :viridis  # You can choose another colormap as needed\n",
    "# Normalize your cctf values to the range of the colormap\n",
    "normalized_cctf = cctf\n",
    "\n",
    "# Add leading spaces to the color bar title to create more space\n",
    "colorbar_title_with_space = \"          cc\"  # Adjust the number of spaces as needed\n",
    "\n",
    "# First plot with colors based on cctf values\n",
    "p1 = scatter(dtf, dvtf, zcolor=normalized_cctf, cmap=my_colormap, markerstrokewidth=0,\n",
    "             colorbar=true, colorbar_title=colorbar_title_with_space, seriestype=:scatter, legend=false,\n",
    "             xticks=(ticks, tick), xrot=-30, ylabel=\"dv/v %\", ylim=(-0.3,0.3),#xlim=(DateTime(2016,3,25), DateTime(2016,12,1)),\n",
    "             size=(1000, 300), left_margin=20Plots.mm, right_margin=10Plots.mm,\n",
    "             bottom_margin=10Plots.mm, dpi=200)\n",
    "plot!(dtf, dvtf, legend=false, xticks=(ticks, tick), xrot=-50,size = (1200 , 350),left_margin = 20Plots.mm, right_margin = 10Plots.mm,bottom_margin = 10Plots.mm, dpi=200)\n",
    "\n",
    "# Display the plotcvh\n",
    "display(p1)\n",
    "#savefig(p1, \"thedrop3stk.png\")\n",
    "#savefig(p1, \"$(d.name)_t$(tmin)-$(tmax)_freq$(mnf)-$(mxf)_stk$(ndaystack)dvvvv.png\")\n",
    "#savefig(p1, \"syntheticdvvvvn.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40798923",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = plot(dtf, cctf, seriestype = :line, ylim = [0.8, 1.05], label = \"cc\", xticks = (ticks, tick), xrot = -30, ylabel=\"cc\", xlabel=\"Date\", legend=false,size=(1500, 500),left_margin = 20Plots.mm, right_margin = 10Plots.mm,bottom_margin = 10Plots.mm, dpi=200)\n",
    "#hline!([0.8], label=\"Threshold\", width=2, color=:red) # Adding a horizontal line at y=0.8\n",
    "savefig(p2, \"thedrop10stkcc.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dbdad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames\n",
    "\n",
    "# Assuming dvt and cct are already defined as 75-element Vector{Float64}\n",
    "df = DataFrame(T = dtf, DVT = dvtf, CCT = cctf)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "CSV.write(\"HYS14B1_083ZZp.csv\", df)\n",
    "#CSV.write(\"synthetic_n.csv\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccbdebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
